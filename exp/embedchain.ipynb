{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qq \"embedchain==0.0.59\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc content has not changed. Skipping creating chunks and embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'161fcad59ba37a28e60a45f5355dab43'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from embedchain import App\n",
    "from embedchain.config import LlmConfig\n",
    "\n",
    "pg_bot = App()\n",
    "pg_bot.add(\"http://paulgraham.com/greatwork.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "  Use the following pieces of context to answer the query at the end.\n",
       "  If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
       "\n",
       "  interesting, which you necessarily will if you're on the right path, the work will probably feel less burdensome than a lot of your peers'.The discoveries are out there, waiting to be made. Why not by you? Notes[1] I don't think you could give a precise definition of what counts as great work. Doing great work means doing something important so well that you expand people's ideas of what's possible. But there's no threshold for importance. It's a matter of degree, and often hard to judge at the\n",
       "\n",
       "  Query: how to do great work?\n",
       "\n",
       "  Helpful Answer:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pg_bot.query(\"how to do great work?\", dry_run=True)\n",
    "Markdown(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "interesting, which you necessarily will if you're on the right path, the work will probably feel less burdensome than a lot of your peers'.The discoveries are out there, waiting to be made. Why not by you? Notes[1] I don't think you could give a precise definition of what counts as great work. Doing great work means doing something important so well that you expand people's ideas of what's possible. But there's no threshold for importance. It's a matter of degree, and often hard to judge at the\n",
       "\n",
       "you must be interested in doing great work. And if so you're already further along than you might realize, because the set of people willing to want to is small.The factors in doing great work are factors in the literal, mathematical sense, and they are: ability, interest, effort, and luck. Luck by definition you can't do anything about, so we can ignore that. And we can assume effort, if you do in fact want to do great work. So the problem boils down to ability and interest. Can you find a"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = pg_bot.retrieve_from_database(\n",
    "    \"how to do great work?\", config=LlmConfig(number_documents=2)\n",
    ")\n",
    "\n",
    "Markdown(\"\\n\\n\".join(contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is originality in choosing problems consid...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question          model\n",
       "0  Why is originality in choosing problems consid...  gpt-3.5-turbo"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastrepl\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "eval = fastrepl.RAGEvaluator(node=fastrepl.RAGAS(metric=\"AnswerRelevancy\"))\n",
    "ds = load_dataset(\"repllabs/questions_how_to_do_great_work\", split=\"processed\")\n",
    "\n",
    "ds = ds.shuffle(seed=8)\n",
    "ds = ds.select(range(4))\n",
    "ds.to_pandas()[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'model', 'answer'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = []\n",
    "for q in ds[\"question\"]:\n",
    "    answer = pg_bot.query(q)\n",
    "    answers.append(answer)\n",
    "\n",
    "ds = ds.add_column(\"answer\", answers)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'model', 'answer', 'result'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = fastrepl.local_runner(evaluator=eval, dataset=ds).run(show_progress=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9305319965767472,\n",
       " 0.9582303203007904,\n",
       " 0.9945522867737369,\n",
       " 0.9199520412420689]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
